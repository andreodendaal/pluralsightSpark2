{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this notebook from Command line - pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.242:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:184"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data = sc.parallelize([1,\"Alice\", 50])\n",
    "simple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'Alice', 50]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'Alice', 50]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = sc.parallelize([[1,\"Alice\", 50], [2, \"Bob\", 80]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'Alice', 50], [2, 'Bob', 80]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = records.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: bigint, _2: string, _3: bigint]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| _1|   _2| _3|\n",
      "+---+-----+---+\n",
      "|  1|Alice| 50|\n",
      "|  2|  Bob| 80|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[18] at parallelize at PythonRDD.scala:175"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize([Row(id=1, name=\"Alice\", score=50),\n",
    "      Row(\n",
    "        id=2,\n",
    "        name=\"Bob\",\n",
    "        score=80    \n",
    "    ),\n",
    "      Row(\n",
    "    id=3,\n",
    "    name=\"Charles\",\n",
    "    score=100    \n",
    "    )]\n",
    "       )    \n",
    "                      \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+\n",
      "| id|   name|score|\n",
      "+---+-------+-----+\n",
      "|  1|  Alice|   50|\n",
      "|  2|    Bob|   80|\n",
      "|  3|Charles|  100|\n",
      "+---+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = data.toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = sc.parallelize([\n",
    "    Row(\n",
    "    col_float=1.44,\n",
    "    col_integer=10,\n",
    "    col_string=\"John\",\n",
    "    col_list=[1,2,3],\n",
    "    col_row=Row(a=10, b=20),\n",
    "    col_dict={\"k1\":0, \"K2\":1},\n",
    "    col_time=datetime(2014,8,2,15,1,5)\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+-----------+---------+--------+----------+-------------------+\n",
      "|          col_dict|col_float|col_integer| col_list| col_row|col_string|           col_time|\n",
      "+------------------+---------+-----------+---------+--------+----------+-------------------+\n",
      "|[k1 -> 0, K2 -> 1]|     1.44|         10|[1, 2, 3]|[10, 20]|      John|2014-08-02 15:01:05|\n",
      "+------------------+---------+-----------+---------+--------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df = complex_data.toDF()\n",
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = sc.parallelize([\n",
    "    Row(\n",
    "        col_float=1.44,\n",
    "        col_integer=10,\n",
    "        col_string=\"John\",\n",
    "        col_list=[1,2,3],\n",
    "        col_row=Row(a=10, b=20),\n",
    "        col_dict={\"k1\":0, \"K2\":1},\n",
    "        col_time=datetime(2014,8,2,15,1,5)\n",
    "    ),\n",
    "    Row(\n",
    "        col_float=1.44,\n",
    "        col_integer=10,\n",
    "        col_string=\"John\",\n",
    "        col_list=[1,2,3],\n",
    "        col_row=Row(a=10, b=20),\n",
    "        col_dict={\"k1\":0, \"K2\":1},\n",
    "        col_time=datetime(2014,8,2,15,1,5)\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+-----------+---------+--------+----------+-------------------+\n",
      "|          col_dict|col_float|col_integer| col_list| col_row|col_string|           col_time|\n",
      "+------------------+---------+-----------+---------+--------+----------+-------------------+\n",
      "|[k1 -> 0, K2 -> 1]|     1.44|         10|[1, 2, 3]|[10, 20]|      John|2014-08-02 15:01:05|\n",
      "|[k1 -> 0, K2 -> 1]|     1.44|         10|[1, 2, 3]|[10, 20]|      John|2014-08-02 15:01:05|\n",
      "+------------------+---------+-----------+---------+--------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df = complex_data.toDF()\n",
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x1434456f160>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sqlContext.range(5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Alice', 50), ('Bob', 60), ('Fred', 71)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|   _1| _2|\n",
      "+-----+---+\n",
      "|Alice| 50|\n",
      "|  Bob| 60|\n",
      "| Fred| 71|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.createDataFrame(data).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "|Alice| 50|\n",
      "|  Bob| 60|\n",
      "| Fred| 71|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.createDataFrame(data, ['Name', 'Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = [\n",
    "    (1.0,\n",
    "     10, \n",
    "     'Alice',\n",
    "     True,\n",
    "     [1, 2, 3],\n",
    "     {\"k1\":0}, \n",
    "     Row(a=1, b=2, c=3),\n",
    "     datetime(2014, 8, 1, 14, 1, 4)),\n",
    "    \n",
    "     (2.0,\n",
    "     10, \n",
    "     'Bob',\n",
    "     False,\n",
    "     [4, 5, 6],\n",
    "     {\"k2\":1}, \n",
    "     Row(a=4, b=5, c=6),\n",
    "     datetime(2016, 8, 1, 14, 1, 5)),\n",
    "    \n",
    "     (3.0,\n",
    "     10, \n",
    "     'Peter',\n",
    "     False,\n",
    "     [7, 8, 9],\n",
    "     {\"k3\":3}, \n",
    "     Row(a=7, b=8, c=9),\n",
    "     datetime(2017, 9, 1, 14, 1, 6))\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----+-----+---------+---------+---------+-------------------+\n",
      "| _1| _2|   _3|   _4|       _5|       _6|       _7|                 _8|\n",
      "+---+---+-----+-----+---------+---------+---------+-------------------+\n",
      "|1.0| 10|Alice| true|[1, 2, 3]|[k1 -> 0]|[1, 2, 3]|2014-08-01 14:01:04|\n",
      "|2.0| 10|  Bob|false|[4, 5, 6]|[k2 -> 1]|[4, 5, 6]|2016-08-01 14:01:05|\n",
      "|3.0| 10|Peter|false|[7, 8, 9]|[k3 -> 3]|[7, 8, 9]|2017-09-01 14:01:06|\n",
      "+---+---+-----+-----+---------+---------+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from datetime import datetime\n",
    "\n",
    "sqlContext.createDataFrame(complex_data).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize([\n",
    "    Row(1, \"Alice\", 50),\n",
    "    Row(2, \"Bob\", 60),\n",
    "    Row(3, \"John\", 70)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = Row('id', 'Name', 'score')\n",
    "students = data.map(lambda r: column_names(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[129] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, Name='Alice', score=50),\n",
       " Row(id=2, Name='Bob', score=60),\n",
       " Row(id=3, Name='John', score=70)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, Name: string, score: bigint]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_df = sqlContext.createDataFrame(students)\n",
    "students_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| id| Name|score|\n",
      "+---+-----+-----+\n",
      "|  1|Alice|   50|\n",
      "|  2|  Bob|   60|\n",
      "|  3| John|   70|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x14344620cc0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.range(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    Row(1, \"Alice\", 50),\n",
    "    Row(2, \"Bob\", 60),\n",
    "    Row(3, \"John\", 70)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| _1|   _2| _3|\n",
      "+---+-----+---+\n",
      "|  1|Alice| 50|\n",
      "|  2|  Bob| 60|\n",
      "|  3| John| 70|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.createDataFrame(data).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "|  #| Name|Score|\n",
      "+---+-----+-----+\n",
      "|  1|Alice|   50|\n",
      "|  2|  Bob|   60|\n",
      "|  3| John|   70|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.createDataFrame(data, ['#','Name', 'Score']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from datetime import datetime\n",
    "\n",
    "complex_data_df = sqlContext.createDataFrame(complex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(_1=1.0, _2=10, _3='Alice', _4=True, _5=[1, 2, 3], _6={'k1': 0}, _7=Row(a=1, b=2, c=3), _8=datetime.datetime(2014, 8, 1, 14, 1, 4))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_data_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----+-----+---------+---------+---------+-------------------+\n",
      "| _1| _2|   _3|   _4|       _5|       _6|       _7|                 _8|\n",
      "+---+---+-----+-----+---------+---------+---------+-------------------+\n",
      "|1.0| 10|Alice| true|[1, 2, 3]|[k1 -> 0]|[1, 2, 3]|2014-08-01 14:01:04|\n",
      "|2.0| 10|  Bob|false|[4, 5, 6]|[k2 -> 1]|[4, 5, 6]|2016-08-01 14:01:05|\n",
      "|3.0| 10|Peter|false|[7, 8, 9]|[k3 -> 3]|[7, 8, 9]|2017-09-01 14:01:06|\n",
      "+---+---+-----+-----+---------+---------+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_string = complex_data_df.collect()[0][2]\n",
    "cell_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_list = complex_data_df.collect()[0][4]\n",
    "cell_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
